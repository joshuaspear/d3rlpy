{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWVdtW83Rz8y"
      },
      "source": [
        "Setup rendering dependencies for Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h56pgW5PRz81"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y xvfb ffmpeg > /dev/null 2>&1\n",
        "!pip install pyvirtualdisplay pygame moviepy > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjIeDwAnRz82"
      },
      "source": [
        "Install d3rlpy and PyTorch with TPU support! It likely fails to install the XLA dependency for the first time. If it's the case, simply restart the runtime and retry this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meFEBhUkRz83"
      },
      "outputs": [],
      "source": [
        "!pip install d3rlpy torch~=2.0.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZjK4rLiRz83"
      },
      "source": [
        "Setup cartpole dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqxnnKMNRz83"
      },
      "outputs": [],
      "source": [
        "import d3rlpy\n",
        "\n",
        "# get CartPole dataset\n",
        "dataset, env = d3rlpy.datasets.get_cartpole()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEkMtKIHRz84"
      },
      "source": [
        "Setup data-driven deep reinforcement learning algorithm with TPU. Currently, it's super slow to train the small architecture. But, you can see it works at least."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kyhhMjcRz84"
      },
      "outputs": [],
      "source": [
        "# get TPU device\n",
        "import torch_xla.core.xla_model as xm\n",
        "device = xm.xla_device()\n",
        "\n",
        "# setup CQL algorithm\n",
        "cql = d3rlpy.algos.DiscreteCQLConfig().create(device=str(device))\n",
        "\n",
        "# start training\n",
        "cql.fit(\n",
        "    dataset,\n",
        "    n_steps=10000,\n",
        "    n_steps_per_epoch=1000,\n",
        "    evaluators={\n",
        "        'environment': d3rlpy.metrics.EnvironmentEvaluator(env), # evaluate with CartPole-v1 environment\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWNyt9WARz84"
      },
      "source": [
        "Setup rendering utilities for Google Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYKQAPhzRz85"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import io\n",
        "import base64\n",
        "\n",
        "from gym.wrappers import RecordVideo\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "# start virtual display\n",
        "display = Display()\n",
        "display.start()\n",
        "\n",
        "# play recorded video\n",
        "def show_video():\n",
        "    mp4list = glob.glob('video/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[0]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        ipythondisplay.display(HTML(data='''\n",
        "            <video alt=\"test\" autoplay loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "            </video>'''.format(encoded.decode('ascii'))))\n",
        "    else:\n",
        "        print(\"Could not find video\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wat4TgcYRz85"
      },
      "source": [
        "Record video!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pvf4zX5LRz85"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "\n",
        "# wrap RecordVideo wrapper\n",
        "env = RecordVideo(gym.make(\"CartPole-v1\", render_mode=\"rgb_array\"), './video')\n",
        "\n",
        "# evaluate\n",
        "d3rlpy.metrics.evaluate_qlearning_with_environment(cql, env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYKphVWYRz85"
      },
      "source": [
        "Let's see how it works!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcRJe7roRz86"
      },
      "outputs": [],
      "source": [
        "show_video()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}